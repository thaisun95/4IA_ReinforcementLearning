{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ed5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration round 1 done\n",
      "Policy iteration round 2 done\n",
      "Policy iteration round 3 done\n",
      "Policy iteration round 4 done\n",
      "Policy converged after 4 rounds.\n",
      "Policy shape: (8192,)\n",
      "Value function (V) sample: [-4.2901458  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from envs.secret.secret_envs_wrapper import SecretEnv0, SecretEnv1, SecretEnv2, SecretEnv3\n",
    "from rl_algorithms.dp_algorithms_secret.policy_iteration import policy_iteration_blackbox\n",
    "# Exemple pour SecretEnv0\n",
    "env = SecretEnv0()\n",
    "policy, V = policy_iteration_blackbox(env, gamma=0.99, num_episodes=5000, max_iterations=20, verbose=True)\n",
    "print(\"Policy shape:\", policy.shape)\n",
    "print(\"Value function (V) sample:\", V[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71a2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration round 1 done\n",
      "Policy iteration round 2 done\n",
      "Policy iteration round 3 done\n",
      "Policy iteration round 4 done\n",
      "Policy converged after 4 rounds.\n",
      "=== SecretEnv1 ===\n",
      "Policy shape: (65536,)\n",
      "Value function (V) sample: [-2.4137991  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "from envs.secret.secret_envs_wrapper import SecretEnv1\n",
    "from rl_algorithms.dp_algorithms_secret.policy_iteration import policy_iteration_blackbox\n",
    "\n",
    "env = SecretEnv1()\n",
    "policy, V = policy_iteration_blackbox(env, gamma=0.99, num_episodes=5000, max_iterations=20, verbose=True)\n",
    "print(\"=== SecretEnv1 ===\")\n",
    "print(\"Policy shape:\", policy.shape)\n",
    "print(\"Value function (V) sample:\", V[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93c06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration round 1 done\n",
      "Policy iteration round 2 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrl_algorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdp_algorithms_secret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy_iteration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m policy_iteration_blackbox\n\u001b[0;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m SecretEnv2()\n\u001b[1;32m----> 5\u001b[0m policy, V \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_iteration_blackbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== SecretEnv2 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, policy\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\said_\\Desktop\\4IA_ReinforcementLearning\\rl_algorithms\\dp_algorithms_secret\\policy_iteration.py:60\u001b[0m, in \u001b[0;36mpolicy_iteration_blackbox\u001b[1;34m(env, gamma, num_episodes, max_iterations, theta, verbose)\u001b[0m\n\u001b[0;32m     58\u001b[0m env\u001b[38;5;241m.\u001b[39mstep(a)\n\u001b[0;32m     59\u001b[0m s_prime \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstate_id()\n\u001b[1;32m---> 60\u001b[0m reward \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mscore() \u001b[38;5;28;01mif\u001b[39;00m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_game_over\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     61\u001b[0m val \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m V[s_prime]\n\u001b[0;32m     62\u001b[0m action_values\u001b[38;5;241m.\u001b[39mappend(val)\n",
      "File \u001b[1;32mc:\\Users\\said_\\Desktop\\4IA_ReinforcementLearning\\envs\\secret\\secret_envs_wrapper.py:404\u001b[0m, in \u001b[0;36mSecretEnv2.is_game_over\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_game_over\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecret_env_2_is_game_over\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from envs.secret.secret_envs_wrapper import SecretEnv2\n",
    "from rl_algorithms.dp_algorithms_secret.policy_iteration import policy_iteration_blackbox\n",
    "\n",
    "env = SecretEnv2()\n",
    "policy, V = policy_iteration_blackbox(env, gamma=0.99, num_episodes=5000, max_iterations=20, verbose=True)\n",
    "print(\"=== SecretEnv2 ===\")\n",
    "print(\"Policy shape:\", policy.shape)\n",
    "print(\"Value function (V) sample:\", V[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration round 1 done\n",
      "Policy iteration round 2 done\n",
      "Policy iteration round 3 done\n",
      "Policy iteration round 4 done\n",
      "Policy iteration round 5 done\n",
      "Policy iteration round 6 done\n",
      "Policy iteration round 7 done\n",
      "Policy iteration round 8 done\n",
      "Policy iteration round 9 done\n",
      "Policy iteration round 10 done\n",
      "Policy iteration round 11 done\n",
      "Policy iteration round 12 done\n",
      "Policy iteration round 13 done\n",
      "Policy iteration round 14 done\n",
      "Policy iteration round 15 done\n",
      "Policy iteration round 16 done\n",
      "Policy iteration round 17 done\n",
      "Policy iteration round 18 done\n",
      "Policy iteration round 19 done\n",
      "Policy iteration round 20 done\n",
      "=== SecretEnv3 ===\n",
      "Policy shape: (65536,)\n",
      "Value function (V) sample: [-2.67403779  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from envs.secret.secret_envs_wrapper import SecretEnv3\n",
    "from rl_algorithms.dp_algorithms_secret.policy_iteration import policy_iteration_blackbox\n",
    "\n",
    "env = SecretEnv3()\n",
    "policy, V = policy_iteration_blackbox(env, gamma=0.99, num_episodes=5000, max_iterations=20, verbose=True)\n",
    "print(\"=== SecretEnv3 ===\")\n",
    "print(\"Policy shape:\", policy.shape)\n",
    "print(\"Value function (V) sample:\", V[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b20ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value iteration round 1 done\n",
      "Value iteration round 2 done\n",
      "Value iteration converged after 2 rounds.\n",
      "Policy shape (env0): (8192,)\n",
      "Value function (env0) sample: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from envs.secret.secret_envs_wrapper import SecretEnv0\n",
    "from rl_algorithms.dp_algorithms_secret.value_iteration import value_iteration_blackbox\n",
    "\n",
    "env0 = SecretEnv0()\n",
    "V0, policy0 = value_iteration_blackbox(env0, gamma=0.99, max_iterations=100, verbose=True)\n",
    "print(\"Policy shape (env0):\", policy0.shape)\n",
    "print(\"Value function (env0) sample:\", V0[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3f597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value iteration round 1 done\n",
      "Value iteration round 2 done\n",
      "Value iteration converged after 2 rounds.\n",
      "Policy shape (env1): (65536,)\n",
      "Value function (env1) sample: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "env1 = SecretEnv1()\n",
    "V1, policy1 = value_iteration_blackbox(env1, gamma=0.99, max_iterations=100, verbose=True)\n",
    "print(\"Policy shape (env1):\", policy1.shape)\n",
    "print(\"Value function (env1) sample:\", V1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75885989",
   "metadata": {},
   "outputs": [],
   "source": [
    "env2 = SecretEnv2()\n",
    "V2, policy2 = value_iteration_blackbox(env2, gamma=0.99, max_iterations=100, verbose=True)\n",
    "print(\"Policy shape (env2):\", policy2.shape)\n",
    "print(\"Value function (env2) sample:\", V2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "env3 = SecretEnv3()\n",
    "V3, policy3 = value_iteration_blackbox(env3, gamma=0.99, max_iterations=100, verbose=True)\n",
    "print(\"Policy shape (env3):\", policy3.shape)\n",
    "print(\"Value function (env3) sample:\", V3[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
